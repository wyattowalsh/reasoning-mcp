"""Token cost estimation for reasoning methods.

This module provides token multipliers for different reasoning methods to help
estimate the total tokens that will be consumed, accounting for the additional
tokens generated by each method's internal reasoning process.
"""

from typing import Protocol


class TokenEstimator(Protocol):
    """Protocol for token estimation strategies."""

    def estimate_tokens(self, text: str) -> int:
        """Estimate token count for given text."""
        ...


# Token multipliers for reasoning methods - accounts for additional tokens
# generated by each method's internal reasoning process
METHOD_TOKEN_MULTIPLIERS: dict[str, float] = {
    "chain_of_thought": 2.5,
    "tree_of_thoughts": 4.0,
    "react": 3.0,
    "self_consistency": 5.0,  # Multiple samples
    "mcts": 6.0,
    "graph_of_thoughts": 4.5,
    "step_back": 2.0,
    "least_to_most": 3.0,
    "self_ask": 2.5,
    "decomposed": 3.5,
    "sequential": 1.5,
    "default": 2.0,
}
