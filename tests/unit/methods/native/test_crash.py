"""Unit tests for CRASH reasoning method."""

from __future__ import annotations

import pytest

from reasoning_mcp.methods.native.crash import (
    CRASH_METADATA,
    CRASHMethod,
)
from reasoning_mcp.models import Session
from reasoning_mcp.models.core import MethodCategory, MethodIdentifier, ThoughtType

# Fixtures


@pytest.fixture
def crash_method() -> CRASHMethod:
    """Create a CRASHMethod instance with default settings."""
    return CRASHMethod()


@pytest.fixture
def custom_crash_method() -> CRASHMethod:
    """Create a CRASHMethod instance with custom settings."""
    return CRASHMethod(
        confidence_threshold=0.7,
        max_strategy_switches=5,
        fallback_strategy="abstract",
    )


@pytest.fixture
def active_session() -> Session:
    """Create an active session for testing."""
    return Session().start()


@pytest.fixture
def inactive_session() -> Session:
    """Create an inactive session for testing."""
    return Session()


# Test Metadata


class TestMetadata:
    """Tests for CRASH metadata."""

    def test_metadata_identifier(self):
        """Test metadata has correct identifier."""
        assert CRASH_METADATA.identifier == MethodIdentifier.CRASH

    def test_metadata_name(self):
        """Test metadata has correct name."""
        assert CRASH_METADATA.name == "CRASH"

    def test_metadata_description(self):
        """Test metadata has descriptive text."""
        assert len(CRASH_METADATA.description) > 0
        assert "confidence" in CRASH_METADATA.description.lower()

    def test_metadata_category(self):
        """Test metadata has correct category."""
        assert CRASH_METADATA.category == MethodCategory.HOLISTIC

    def test_metadata_tags(self):
        """Test metadata has expected tags."""
        expected_tags = {
            "adaptive",
            "confidence",
            "strategy-switching",
            "resilient",
            "monitoring",
            "fallback",
            "holistic",
        }
        assert expected_tags.issubset(CRASH_METADATA.tags)

    def test_metadata_complexity(self):
        """Test metadata complexity is high (8)."""
        assert CRASH_METADATA.complexity == 8

    def test_metadata_supports_branching(self):
        """Test metadata indicates branching support."""
        assert CRASH_METADATA.supports_branching is True

    def test_metadata_supports_revision(self):
        """Test metadata indicates revision support."""
        assert CRASH_METADATA.supports_revision is True

    def test_metadata_requires_context(self):
        """Test metadata indicates no context requirement."""
        assert CRASH_METADATA.requires_context is False

    def test_metadata_min_thoughts(self):
        """Test metadata has minimum thoughts requirement."""
        assert CRASH_METADATA.min_thoughts == 3

    def test_metadata_max_thoughts(self):
        """Test metadata has unlimited max thoughts (0)."""
        assert CRASH_METADATA.max_thoughts == 0


# Test Initialization


class TestInitialization:
    """Tests for CRASHMethod initialization."""

    def test_init_default_parameters(self):
        """Test initialization with default parameters."""
        crash = CRASHMethod()
        assert crash.confidence_threshold == 0.6
        assert crash.max_strategy_switches == 3
        assert crash.fallback_strategy == "decompose"

    def test_init_custom_parameters(self):
        """Test initialization with custom parameters."""
        crash = CRASHMethod(
            confidence_threshold=0.75,
            max_strategy_switches=5,
            fallback_strategy="abstract",
        )
        assert crash.confidence_threshold == 0.75
        assert crash.max_strategy_switches == 5
        assert crash.fallback_strategy == "abstract"

    def test_init_invalid_threshold_below_zero(self):
        """Test initialization fails with threshold < 0."""
        with pytest.raises(ValueError, match="confidence_threshold must be 0.0-1.0"):
            CRASHMethod(confidence_threshold=-0.1)

    def test_init_invalid_threshold_above_one(self):
        """Test initialization fails with threshold > 1."""
        with pytest.raises(ValueError, match="confidence_threshold must be 0.0-1.0"):
            CRASHMethod(confidence_threshold=1.5)

    def test_init_invalid_max_switches_zero(self):
        """Test initialization fails with max_strategy_switches=0."""
        with pytest.raises(ValueError, match="max_strategy_switches must be >= 1"):
            CRASHMethod(max_strategy_switches=0)

    def test_init_invalid_max_switches_negative(self):
        """Test initialization fails with negative max_strategy_switches."""
        with pytest.raises(ValueError, match="max_strategy_switches must be >= 1"):
            CRASHMethod(max_strategy_switches=-3)

    def test_init_invalid_fallback_strategy(self):
        """Test initialization fails with invalid fallback strategy."""
        with pytest.raises(ValueError, match="fallback_strategy must be one of"):
            CRASHMethod(fallback_strategy="invalid_strategy")

    def test_strategies_defined(self):
        """Test that all strategies are defined."""
        expected_strategies = {
            "direct",
            "decompose",
            "analogize",
            "abstract",
            "verify",
        }
        assert set(CRASHMethod.STRATEGIES.keys()) == expected_strategies

    @pytest.mark.asyncio
    async def test_initialize_method(self, crash_method: CRASHMethod):
        """Test initialize() method executes successfully."""
        await crash_method.initialize()
        assert crash_method._initialized is True
        assert crash_method._switch_count == 0
        assert crash_method._step_counter == 0

    @pytest.mark.asyncio
    async def test_initialize_resets_state(self, crash_method: CRASHMethod):
        """Test initialize() resets internal state."""
        # Manually set some state
        crash_method._switch_count = 5
        crash_method._confidence_history = [0.5, 0.6]
        crash_method._strategy_history = ["direct", "decompose"]

        # Initialize should reset
        await crash_method.initialize()
        assert crash_method._switch_count == 0
        assert crash_method._confidence_history == []
        assert crash_method._strategy_history == []
        assert crash_method._current_strategy == "direct"

    @pytest.mark.asyncio
    async def test_health_check_before_initialize(self):
        """Test health_check() returns False before initialize()."""
        crash = CRASHMethod()
        result = await crash.health_check()
        assert result is False

    @pytest.mark.asyncio
    async def test_health_check_after_initialize(self, crash_method: CRASHMethod):
        """Test health_check() returns True after initialize()."""
        await crash_method.initialize()
        result = await crash_method.health_check()
        assert result is True


# Test Properties


class TestProperties:
    """Tests for CRASHMethod properties."""

    def test_identifier_property(self, crash_method: CRASHMethod):
        """Test identifier property returns correct value."""
        assert crash_method.identifier == MethodIdentifier.CRASH

    def test_name_property(self, crash_method: CRASHMethod):
        """Test name property returns correct value."""
        assert crash_method.name == "CRASH"

    def test_description_property(self, crash_method: CRASHMethod):
        """Test description property returns correct value."""
        assert len(crash_method.description) > 0
        assert "confidence" in crash_method.description.lower()

    def test_category_property(self, crash_method: CRASHMethod):
        """Test category property returns correct value."""
        assert crash_method.category == MethodCategory.HOLISTIC


# Test Basic Execution


class TestBasicExecution:
    """Tests for basic execute() functionality."""

    @pytest.mark.asyncio
    async def test_execute_creates_initial_thought(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test execute() creates initial thought."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test problem")

        # Should have created thoughts
        assert active_session.thought_count > 0
        assert graph.root_id is not None

        # Root should be in graph
        root = graph.nodes[graph.root_id]
        assert root.type == ThoughtType.INITIAL
        assert root.method_id == MethodIdentifier.CRASH

    @pytest.mark.asyncio
    async def test_execute_without_initialize(self, active_session: Session):
        """Test execute() fails without initialize()."""
        crash = CRASHMethod()
        with pytest.raises(RuntimeError, match="must be initialized"):
            await crash.execute(active_session, "Test")

    @pytest.mark.asyncio
    async def test_execute_with_inactive_session(
        self, crash_method: CRASHMethod, inactive_session: Session
    ):
        """Test execute() fails with inactive session."""
        await crash_method.initialize()
        with pytest.raises(ValueError, match="Session must be active"):
            await crash_method.execute(inactive_session, "Test")

    @pytest.mark.asyncio
    async def test_execute_sets_initial_confidence(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test execute() sets initial confidence to 0.7."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test problem")

        root = graph.nodes[graph.root_id]
        assert root.confidence == 0.7

    @pytest.mark.asyncio
    async def test_execute_uses_default_strategy(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test execute() uses direct strategy by default."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test problem")

        root = graph.nodes[graph.root_id]
        assert root.metadata["strategy"] == "direct"
        assert "direct" in crash_method._strategy_history

    @pytest.mark.asyncio
    async def test_execute_with_custom_initial_strategy(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test execute() respects initial_strategy from context."""
        await crash_method.initialize()
        graph = await crash_method.execute(
            active_session, "Test", context={"initial_strategy": "decompose"}
        )

        root = graph.nodes[graph.root_id]
        assert root.metadata["strategy"] == "decompose"

    @pytest.mark.asyncio
    async def test_execute_includes_metadata(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test execute() includes complete metadata."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test problem")

        root = graph.nodes[graph.root_id]
        assert "strategy" in root.metadata
        assert "confidence_threshold" in root.metadata
        assert "switch_count" in root.metadata
        assert "max_switches" in root.metadata
        assert "confidence_history" in root.metadata
        assert "strategy_history" in root.metadata


# Test Confidence Tracking


class TestConfidenceTracking:
    """Tests for confidence tracking and assessment."""

    @pytest.mark.asyncio
    async def test_confidence_history_tracked(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test confidence history is tracked across reasoning steps."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        # Initial execution should have one confidence value
        assert len(crash_method._confidence_history) == 1

        # Continue reasoning
        await crash_method.continue_reasoning(active_session, graph)
        assert len(crash_method._confidence_history) == 2

    @pytest.mark.asyncio
    async def test_confidence_with_positive_feedback(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test confidence increases with positive feedback."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        initial_confidence = crash_method._confidence_history[-1]

        # Continue with positive feedback
        await crash_method.continue_reasoning(
            active_session, graph, feedback="good progress, working well"
        )

        # Confidence should increase or stay high
        new_confidence = crash_method._confidence_history[-1]
        assert new_confidence >= initial_confidence - 0.1  # Allow small variance

    @pytest.mark.asyncio
    async def test_confidence_with_negative_feedback(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test confidence decreases with negative feedback."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        # Continue with negative feedback
        await crash_method.continue_reasoning(
            active_session, graph, feedback="struggling with this approach"
        )

        # Confidence should decrease
        new_confidence = crash_method._confidence_history[-1]
        assert new_confidence < 0.7  # Initial was 0.7

    @pytest.mark.asyncio
    async def test_confidence_bounds_enforced(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test confidence stays within 0.0-1.0 bounds."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        # Continue multiple times with extreme feedback
        for _ in range(5):
            graph = await crash_method.continue_reasoning(
                active_session, graph, feedback="extremely difficult and unclear"
            )

        # All confidence values should be bounded
        for conf in crash_method._confidence_history:
            assert 0.0 <= conf <= 1.0


# Test Configuration


class TestConfiguration:
    """Tests for configuration via context and initialization."""

    @pytest.mark.asyncio
    async def test_context_overrides_threshold(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test context can override confidence_threshold."""
        await crash_method.initialize()
        graph = await crash_method.execute(
            active_session, "Test", context={"confidence_threshold": 0.8}
        )

        root = graph.nodes[graph.root_id]
        assert root.metadata["confidence_threshold"] == 0.8

    @pytest.mark.asyncio
    async def test_invalid_initial_strategy_falls_back(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test invalid initial_strategy falls back to direct."""
        await crash_method.initialize()
        graph = await crash_method.execute(
            active_session, "Test", context={"initial_strategy": "invalid"}
        )

        root = graph.nodes[graph.root_id]
        assert root.metadata["strategy"] == "direct"

    @pytest.mark.asyncio
    async def test_empty_context_uses_defaults(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test empty context uses default parameters."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test", context={})

        root = graph.nodes[graph.root_id]
        assert root.metadata["strategy"] == "direct"
        assert root.metadata["confidence_threshold"] == 0.6


# Test Continue Reasoning


class TestContinueReasoning:
    """Tests for continue_reasoning() method."""

    @pytest.mark.asyncio
    async def test_continue_reasoning_creates_thought(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test continue_reasoning() creates new thought."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        initial_count = active_session.thought_count
        initial_node_count = graph.node_count

        updated_graph = await crash_method.continue_reasoning(active_session, graph)

        # Should have added thoughts
        assert active_session.thought_count > initial_count
        assert updated_graph.node_count > initial_node_count

    @pytest.mark.asyncio
    async def test_continue_reasoning_without_initialize(self, active_session: Session):
        """Test continue_reasoning() fails without initialize()."""
        crash = CRASHMethod()
        graph = active_session.graph

        with pytest.raises(RuntimeError, match="must be initialized"):
            await crash.continue_reasoning(active_session, graph)

    @pytest.mark.asyncio
    async def test_continue_reasoning_with_inactive_session(
        self, crash_method: CRASHMethod, inactive_session: Session
    ):
        """Test continue_reasoning() fails with inactive session."""
        await crash_method.initialize()
        graph = inactive_session.graph

        with pytest.raises(ValueError, match="Session must be active"):
            await crash_method.continue_reasoning(inactive_session, graph)

    @pytest.mark.asyncio
    async def test_continue_reasoning_with_invalid_graph(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test continue_reasoning() fails with invalid graph."""
        await crash_method.initialize()
        graph = active_session.graph  # Empty graph

        with pytest.raises(ValueError, match="must have a valid root"):
            await crash_method.continue_reasoning(active_session, graph)

    @pytest.mark.asyncio
    async def test_continue_reasoning_increments_step_counter(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test continue_reasoning() increments step counter."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        assert crash_method._step_counter == 1

        await crash_method.continue_reasoning(active_session, graph)
        assert crash_method._step_counter == 2

    @pytest.mark.asyncio
    async def test_continue_reasoning_with_feedback(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test continue_reasoning() includes feedback."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        updated_graph = await crash_method.continue_reasoning(
            active_session, graph, feedback="Try a different approach"
        )

        # Find the new thought
        new_thoughts = [n for n in updated_graph.nodes.values() if n.step_number == 2]
        assert len(new_thoughts) > 0
        new_thought = new_thoughts[0]
        assert new_thought.metadata.get("feedback") == "Try a different approach"


# Test Strategy Switching


class TestStrategySwitching:
    """Tests for automatic strategy switching."""

    @pytest.mark.asyncio
    async def test_strategy_switch_on_low_confidence(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test strategy switches when confidence drops below threshold."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        # Force low confidence with negative feedback
        await crash_method.continue_reasoning(
            active_session, graph, feedback="very difficult, unclear, stuck"
        )

        # Should have switched strategies
        assert crash_method._switch_count >= 1
        assert len(crash_method._strategy_history) >= 2

    @pytest.mark.asyncio
    async def test_no_switch_on_high_confidence(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test strategy doesn't switch when confidence is high."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        # Provide positive feedback to maintain high confidence
        await crash_method.continue_reasoning(
            active_session, graph, feedback="excellent progress, very clear"
        )

        # Should not have switched
        assert crash_method._switch_count == 0
        assert len(crash_method._strategy_history) == 1

    @pytest.mark.asyncio
    async def test_switch_creates_branch_thought(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test strategy switch creates BRANCH type thought."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        # Force a switch
        updated_graph = await crash_method.continue_reasoning(
            active_session, graph, feedback="struggling badly"
        )

        # Find the switch thought
        branch_thoughts = [n for n in updated_graph.nodes.values() if n.type == ThoughtType.BRANCH]

        if crash_method._switch_count > 0:
            assert len(branch_thoughts) > 0

    @pytest.mark.asyncio
    async def test_switch_metadata_includes_switch_info(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test switch thought includes switch metadata."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        # Force a switch
        updated_graph = await crash_method.continue_reasoning(
            active_session, graph, feedback="very unclear and difficult"
        )

        # Get the latest thought
        leaves = [updated_graph.nodes[leaf_id] for leaf_id in updated_graph.leaf_ids]
        latest = max(leaves, key=lambda n: n.step_number)

        assert "switched" in latest.metadata
        assert "strategy" in latest.metadata

    @pytest.mark.asyncio
    async def test_max_switches_enforced(self, crash_method: CRASHMethod, active_session: Session):
        """Test max_strategy_switches limit is enforced."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        # Try to force many switches
        for _ in range(10):
            graph = await crash_method.continue_reasoning(
                active_session, graph, feedback="struggling, stuck, unclear"
            )

        # Should not exceed max switches
        assert crash_method._switch_count <= crash_method.max_strategy_switches

    @pytest.mark.asyncio
    async def test_strategy_selection_avoids_recent(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test strategy selection avoids recently used strategies."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        # Force multiple switches
        for _ in range(3):
            graph = await crash_method.continue_reasoning(
                active_session, graph, feedback="difficult and unclear"
            )

        # If switches occurred, strategies should be different
        if crash_method._switch_count > 0:
            strategies_used = set(crash_method._strategy_history)
            assert len(strategies_used) > 1


# Test Multiple Strategies


class TestMultipleStrategies:
    """Tests for different reasoning strategies."""

    def test_all_strategies_have_descriptions(self):
        """Test all strategies have descriptions."""
        for _strategy, description in CRASHMethod.STRATEGIES.items():
            assert len(description) > 0
            assert isinstance(description, str)

    @pytest.mark.asyncio
    async def test_direct_strategy(self, crash_method: CRASHMethod, active_session: Session):
        """Test direct strategy execution."""
        await crash_method.initialize()
        graph = await crash_method.execute(
            active_session, "Test", context={"initial_strategy": "direct"}
        )

        root = graph.nodes[graph.root_id]
        assert root.metadata["strategy"] == "direct"
        assert "direct" in root.content.lower()

    @pytest.mark.asyncio
    async def test_decompose_strategy(self, crash_method: CRASHMethod, active_session: Session):
        """Test decompose strategy execution."""
        await crash_method.initialize()
        graph = await crash_method.execute(
            active_session, "Test", context={"initial_strategy": "decompose"}
        )

        root = graph.nodes[graph.root_id]
        assert root.metadata["strategy"] == "decompose"

    @pytest.mark.asyncio
    async def test_analogize_strategy(self, crash_method: CRASHMethod, active_session: Session):
        """Test analogize strategy execution."""
        await crash_method.initialize()
        graph = await crash_method.execute(
            active_session, "Test", context={"initial_strategy": "analogize"}
        )

        root = graph.nodes[graph.root_id]
        assert root.metadata["strategy"] == "analogize"

    @pytest.mark.asyncio
    async def test_abstract_strategy(self, crash_method: CRASHMethod, active_session: Session):
        """Test abstract strategy execution."""
        await crash_method.initialize()
        graph = await crash_method.execute(
            active_session, "Test", context={"initial_strategy": "abstract"}
        )

        root = graph.nodes[graph.root_id]
        assert root.metadata["strategy"] == "abstract"

    @pytest.mark.asyncio
    async def test_verify_strategy(self, crash_method: CRASHMethod, active_session: Session):
        """Test verify strategy execution."""
        await crash_method.initialize()
        graph = await crash_method.execute(
            active_session, "Test", context={"initial_strategy": "verify"}
        )

        root = graph.nodes[graph.root_id]
        assert root.metadata["strategy"] == "verify"


# Test Confidence Gates


class TestConfidenceGates:
    """Tests for gating decisions based on confidence."""

    @pytest.mark.asyncio
    async def test_continuation_when_above_threshold(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test CONTINUATION thought when confidence above threshold."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        # Maintain confidence with positive feedback
        updated_graph = await crash_method.continue_reasoning(
            active_session, graph, feedback="working very well"
        )

        # Find the new thought
        new_thoughts = [n for n in updated_graph.nodes.values() if n.step_number == 2]
        assert len(new_thoughts) > 0
        new_thought = new_thoughts[0]

        # Should be continuation, not branch
        assert new_thought.type == ThoughtType.CONTINUATION

    @pytest.mark.asyncio
    async def test_branch_when_below_threshold(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test BRANCH thought when confidence below threshold."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        # Drop confidence with negative feedback
        updated_graph = await crash_method.continue_reasoning(
            active_session, graph, feedback="struggling badly, very unclear"
        )

        # Find the new thought
        new_thoughts = [n for n in updated_graph.nodes.values() if n.step_number == 2]

        if crash_method._switch_count > 0:
            new_thought = new_thoughts[0]
            assert new_thought.type == ThoughtType.BRANCH

    @pytest.mark.asyncio
    async def test_custom_threshold_respected(self, active_session: Session):
        """Test custom threshold is respected."""
        crash = CRASHMethod(confidence_threshold=0.8)
        await crash.initialize()
        graph = await crash.execute(active_session, "Test", context={"confidence_threshold": 0.9})

        root = graph.nodes[graph.root_id]
        assert root.metadata["confidence_threshold"] == 0.9


# Test Fallback Handling


class TestFallbackHandling:
    """Tests for fallback behavior when strategies exhausted."""

    @pytest.mark.asyncio
    async def test_fallback_strategy_used(
        self, custom_crash_method: CRASHMethod, active_session: Session
    ):
        """Test fallback strategy is used when all strategies tried."""
        await custom_crash_method.initialize()
        graph = await custom_crash_method.execute(active_session, "Test")

        # Force many switches to potentially use fallback
        for _ in range(6):
            graph = await custom_crash_method.continue_reasoning(
                active_session, graph, feedback="struggling"
            )

        # Fallback strategy should be in history if exhausted
        if custom_crash_method._switch_count >= 5:
            assert "abstract" in custom_crash_method._strategy_history

    @pytest.mark.asyncio
    async def test_conclusion_after_max_switches(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test conclusion is created after reaching max switches."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        # Force max switches
        for _ in range(4):
            graph = await crash_method.continue_reasoning(
                active_session, graph, feedback="unclear and difficult"
            )

        # Should have conclusion thought
        conclusion_thoughts = [n for n in graph.nodes.values() if n.type == ThoughtType.CONCLUSION]

        if crash_method._switch_count >= crash_method.max_strategy_switches:
            assert len(conclusion_thoughts) > 0

    @pytest.mark.asyncio
    async def test_conclusion_on_high_confidence(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test conclusion is created when confidence reaches 0.9+."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        # Force high confidence
        crash_method._confidence_history[-1] = 0.95

        updated_graph = await crash_method.continue_reasoning(
            active_session, graph, feedback="excellent, perfect clarity"
        )

        # Should have conclusion thought if confidence >= 0.9
        conclusion_thoughts = [
            n for n in updated_graph.nodes.values() if n.type == ThoughtType.CONCLUSION
        ]

        # May have conclusion if confidence reached 0.9
        if any(c >= 0.9 for c in crash_method._confidence_history):
            assert len(conclusion_thoughts) >= 0  # May or may not have created one yet


# Test Edge Cases


class TestEdgeCases:
    """Tests for edge cases and boundary conditions."""

    @pytest.mark.asyncio
    async def test_empty_input_text(self, crash_method: CRASHMethod, active_session: Session):
        """Test with empty input text."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "")

        assert graph.root_id is not None
        assert active_session.thought_count > 0

    @pytest.mark.asyncio
    async def test_very_long_input_text(self, crash_method: CRASHMethod, active_session: Session):
        """Test with very long input text."""
        long_input = "Complex problem " * 200
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, long_input)

        assert graph.root_id is not None
        assert active_session.thought_count > 0

    @pytest.mark.asyncio
    async def test_special_characters_in_input(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test with special characters in input."""
        special_input = "Test: @#$%^&*() æµ‹è¯• Ã©mojis ðŸ¤”ðŸ’¡"
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, special_input)

        assert graph.root_id is not None

    @pytest.mark.asyncio
    async def test_oscillation_prevention(self, crash_method: CRASHMethod, active_session: Session):
        """Test that strategy oscillation is prevented."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        # Force multiple switches
        for _ in range(4):
            graph = await crash_method.continue_reasoning(active_session, graph, feedback="unclear")

        # Check that we don't immediately revisit strategies
        history = crash_method._strategy_history
        if len(history) >= 3:
            # Last strategy should not be same as second-to-last
            # (unless we've exhausted all options)
            if len(set(CRASHMethod.STRATEGIES.keys())) > 2:
                history[-2:]
                # Allow same strategy only if we've cycled through all
                assert True  # Oscillation prevention is best-effort

    @pytest.mark.asyncio
    async def test_quality_score_calculation(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test quality score is calculated correctly."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        root = graph.nodes[graph.root_id]
        assert root.quality_score is not None
        assert 0.0 <= root.quality_score <= 1.0

    @pytest.mark.asyncio
    async def test_recovery_rate_calculation(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test recovery rate is calculated correctly."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        # Continue a few times
        for i in range(3):
            feedback = "good progress" if i % 2 == 0 else "struggling"
            graph = await crash_method.continue_reasoning(active_session, graph, feedback=feedback)

        recovery_rate = crash_method._calculate_recovery_rate()
        assert 0.0 <= recovery_rate <= 1.0

    @pytest.mark.asyncio
    async def test_conclusion_includes_stats(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test conclusion thought includes statistics."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        # Force conclusion by reaching max switches
        for _ in range(4):
            graph = await crash_method.continue_reasoning(
                active_session, graph, feedback="difficult"
            )

        # Find conclusion if it exists
        conclusion_thoughts = [n for n in graph.nodes.values() if n.type == ThoughtType.CONCLUSION]

        if len(conclusion_thoughts) > 0:
            conclusion = conclusion_thoughts[0]
            assert "is_conclusion" in conclusion.metadata
            assert "total_switches" in conclusion.metadata
            assert "final_strategy" in conclusion.metadata
            assert "average_confidence" in conclusion.metadata
            assert "recovery_rate" in conclusion.metadata

    @pytest.mark.asyncio
    async def test_threshold_at_boundaries(self):
        """Test threshold at boundary values (0.0 and 1.0)."""
        # Test with threshold = 0.0 (never switch)
        crash1 = CRASHMethod(confidence_threshold=0.0)
        session1 = Session().start()
        await crash1.initialize()
        graph1 = await crash1.execute(session1, "Test")
        await crash1.continue_reasoning(session1, graph1, feedback="struggling")
        # Should not switch since threshold is 0.0
        assert crash1._switch_count == 0

        # Test with threshold = 1.0 (always switch)
        crash2 = CRASHMethod(confidence_threshold=1.0)
        session2 = Session().start()
        await crash2.initialize()
        graph2 = await crash2.execute(session2, "Test")
        await crash2.continue_reasoning(session2, graph2)
        # Should switch since confidence < 1.0
        assert crash2._switch_count >= 1

    @pytest.mark.asyncio
    async def test_single_switch_allowed(self):
        """Test with max_strategy_switches=1."""
        crash = CRASHMethod(max_strategy_switches=1, confidence_threshold=0.8)
        session = Session().start()
        await crash.initialize()
        graph = await crash.execute(session, "Test")

        # Force multiple switch attempts
        for _ in range(3):
            graph = await crash.continue_reasoning(session, graph, feedback="struggling badly")

        # Should not exceed max of 1 switch
        assert crash._switch_count <= 1

    @pytest.mark.asyncio
    async def test_multiple_continue_calls(
        self, crash_method: CRASHMethod, active_session: Session
    ):
        """Test multiple continue_reasoning calls work correctly."""
        await crash_method.initialize()
        graph = await crash_method.execute(active_session, "Test")

        # Continue multiple times
        for i in range(5):
            graph = await crash_method.continue_reasoning(
                active_session, graph, feedback=f"Step {i}"
            )

        # Should have created multiple thoughts
        assert active_session.thought_count >= 6  # Initial + 5 continuations
        assert crash_method._step_counter >= 6
